{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part (#6) revolves all around eigenvalues, eigenvectors, and corresponding matrix decompositions.\n",
    "Let's start with initialization as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                # basic arrays, vectors, matrices\n",
    "import scipy as sp                # matrix linear algebra \n",
    "\n",
    "import matplotlib                 # plotting\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style>.output_png { display: table-cell; text-align: center; vertical-align: middle; }</style>\"\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 0**: For more information on Numpy in general, and arrays in particular have a look at the following tutorials:\n",
    "\n",
    "- [Numpy Tutorial for Beginners](https://www.kaggle.com/legendadnan/numpy-tutorial-for-beginners-data-science)\n",
    "- [Python Numpy Tutorial with Jupyter and Colab](https://cs231n.github.io/python-numpy-tutorial/)\n",
    "- [Numpy Tutorials](https://numpy.org/numpy-tutorials/)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Power Iteration to Compute the Largest Eigenpair\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the course, we discussed briefly several methods to compute eigenvalues of a matrix $A$. Among these, the *Power Iteration* is the simplest. However, it is a good illustration of the general idea behind eigenvalue algorithms. It calculates the largest eigenvalue and the corresponding eigenvector in an iterative manner by repeated application of $A$ to a vector $\\mathbf{b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 1**: Complete the function `power_iteration` below to implement the power iteration algorithm to compute the largest eigenpair, given the square matrix `A`. The function should have the following properties:\n",
    "\n",
    "- It should return the sequence of $\\mu_k$ and $\\mathbf{b}$, where $\\mu_k$ is the Rayleigh coefficient obtained in the $k$-th iteration (This is used for visual verification in the code below the function by plotting the $\\mu_k$). The other output $\\mathbf{b}$ is the approximation of the eigenvector.\n",
    "- `power_iteration` should terminate if either the maximum number of iterations (`maxiter`) is reached, or if $(\\mu_k,b_k)$ is (numerically) an eigenpair, i.e. $Ab_k$ and $\\mu_k b_k$ are close. You may use [`numpy.allclose`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html) to check this.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iteration(A, maxiter = 50):\n",
    "    \"\"\"perform power iteration on A and return the sequence of Rayleigh coefficients\"\"\"\n",
    "    b = np.random.random(A.shape[1])\n",
    "    mu = [] # We went with the empty list instead of the list full of zeros, to be able to append new elements to it, without going out of bounds :-)\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        b_new = A@b / np.linalg.norm(A@b) # b_new would pretty much change every time, since we use it's old value to compute the new one, after every iteration\n",
    "        mu_current = (b.T@A@b) / (b.T@b) # The Rayleigh coefficient is calculated every itteration, and corresponds to the current corresponding eigenvector.\n",
    "        mu.append(mu_current) # each one is added to the array\n",
    "        \n",
    "        if np.allclose(A @ b, mu_current * b):\n",
    "            mu = np.asarray(mu) #np.asarray to make sure that we get a NumPy Array.\n",
    "            return mu,b \n",
    "        b = b_new\n",
    "        \n",
    "    mu = np.asarray(mu)\n",
    "    \n",
    "    return mu,b     \n",
    "\n",
    "\n",
    "# test power iteration (largest eigenvalue of A = 18)\n",
    "A = np.array([[9, 0, 3], [4, 6, 12], [15, 9, 3]])\n",
    "\n",
    "mu, b = power_iteration(A)\n",
    "\n",
    "print( \"largest eigenvalue =\", mu[-1], \"(%d iterations)\"%len(mu) )\n",
    "print( \"corresponding eigenvector = \",b)\n",
    "# visualize the convergence of the Rayleigh coefficients\n",
    "\n",
    "fig = plt.plot( mu,linewidth=4.0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the algorithm is correct, it should return the maximum eigenvalue 18 of $A$ after a few (< 20) iterations.\n",
    "\n",
    "Let's inspect convergence by plotting $\\Delta_k = |\\mu_{k+1} - \\mu_k|$, i.e. the order of magnitude of successive updates, in a logarithmic plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(ax, mu):\n",
    "    delta = np.abs(mu[1:]-mu[:-1])\n",
    "    ax.plot(delta)\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True)\n",
    "    \n",
    "plot_convergence(plt.gca(), mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 2**: visualize and compare the convergence for the following three matrices:\n",
    "\n",
    "$$A_1 = \\mathrm{diag}(10,2,1), \\ A_2 = \\mathrm{diag}(10,8,1),\\ A_3 = \\mathrm{diag}(10,9.9,1).$$\n",
    "\n",
    "What is the explanation for the drastically differing convergence behavior?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualization\"\"\"\n",
    "\n",
    "A1 = np.diag([10,2,1])\n",
    "A2 = np.diag([10,8,1])\n",
    "A3 = np.diag([10,9.9,1])\n",
    "\n",
    "AA = np.array([A1,A2,A3])\n",
    "\n",
    "# for i in range(len(AA)):\n",
    "#     plot_convergence(plt.gca(), power_iteration(AA[i])[0]) # 0 since we want to get back mu for every interation\n",
    "\n",
    "for i in AA: # We get each element one after the other. (A1, ...)\n",
    "    mue = power_iteration(i)[0] # 0 since we want to get back mu for every interation\n",
    "    bb = power_iteration(i)[1] # 1 to get b\n",
    "    plot_convergence(plt.gca(), mue)\n",
    "    \n",
    "    print( \"largest eigenvalue =\", mue[-1],\"second largest eigenvalue =\", mue[-2], \"(%d iterations)\"%len(mue) )\n",
    "    print( \"corresponding eigenvector = \",bb)\n",
    "\n",
    "\"\"\"Explanation\"\"\"\n",
    "\n",
    "# Power Iteration tends to converge the fastest, the greater the separations between the magnitudes of the Eigenvalues are.\n",
    "# So convergence would depend on the ratio of the largest to the second largest Eigenvalues.\n",
    "# In our case A2 and A3 would look the most similar to each other(allbeit not so much some times), than they would to A1.\n",
    "# A1's first two largest Eigenvalues have a clear separation, so it tries to converge with as few iterations as possible, and stabilizes towards its largest eigenvalue.\n",
    "# A1 can be identified as the blue line, and A2 and A3 would be the orange and green lines respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### QR Decomposition using the Householder Transformations\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In exercise 5, we have seen the QR decomposition of a matrix using the Gram-Schmidt process. In this exercise, the task is to implement it using the more stable Householder transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 3**: Complete the function `QR_decomposition_Householder` below to implement the QR decomposition of the given square matrix `A`. The function should simply return the $Q$ and $R$ matrices as outputs. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QR Decomposition with Python and NumPy, Quantstart, Stand 13.12.23, URL: https://www.quantstart.com/articles/QR-Decomposition-with-Python-and-NumPy/\n",
    "Bei der def householder(A) haben wir geschaut, wie die Implementation mit Household aussehen kann,\n",
    "jedoch haben wir unsere Implementation wie folgt angepasst.\n",
    "Besonders Schwierig war die Einschätzung der range.\n",
    "\"\"\"\n",
    "# Zuerst Hilfsmethoden. Norm normalisiert für einen Vektor x, während mult_matrix nur 2 Matrizen der selben Dimension multipliziert.\n",
    "\n",
    "def norm(x):\n",
    "    return np.sqrt(sum([x_i**2 for x_i in x]))\n",
    "\n",
    "def mult_matrix(M, N):                                                                  \n",
    "    return np.dot(M,N)\n",
    "\n",
    "def QR_decomposition_Householder(A):\n",
    "    \"\"\"\n",
    "    Führt eine auf Householder-Reflexionen basierende QR-Zerlegung der                                               \n",
    "    Matrix A. Die Funktion gibt Q, eine orthogonale Matrix und R, eine                                                  \n",
    "    obere Dreiecksmatrix, so dass A = QR ist.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "        \n",
    "    Q = np.identity(n)    \n",
    "    R = np.copy(A)\n",
    "    I = np.identity(n)\n",
    "\n",
    "    \n",
    "\n",
    "    for j in range(n-1): # n * m Matrix! n = m v n != m\n",
    "        for i in range(n-1):\n",
    "            x = R[j:, j]  # Von der Spalte j n der Reihe j abwärts\n",
    "            z = I[j:, j]  \n",
    "        sign = -1 if x[0] < 0 else 1 if x[0] > 0 else 0 # definiert das Vorzeichen!\n",
    "        x_normalized = np.multiply(sign, norm(x)) # Vorzeichen auf die Normalisierung von x anwenden\n",
    "\n",
    "        v_1 = x + x_normalized * z # x + ||x|| * z\n",
    "        v_1_normalized = norm(v_1)\n",
    "        v = v_1 / v_1_normalized\n",
    "\n",
    "        Q_min = np.identity(n - j) - 2.0 * np.outer(v, v) # Definition outer: outer product of two vectors. First input vector. Input is flattened if not already 1-dimensional.\n",
    "\n",
    "        Q_t = np.identity(n) \n",
    "        Q_t[j:, j:] = Q_min # Für obere Dreiecksmatrix [j:, j:]\n",
    "        \n",
    "        Q = mult_matrix(Q, Q_t)\n",
    "        R = mult_matrix(Q_t, R) \n",
    "\n",
    "    return Q,R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below, we can check the correctness of the implementation on a test matrix using the identities $A = QR$ and $Q^\\top Q = I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(4,4)\n",
    "Q,R = QR_decomposition_Householder(A)\n",
    "Acheck = Q@R\n",
    "print(A-Acheck)\n",
    "Icheck = np.transpose(Q)@Q\n",
    "print(Icheck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Computing Eigenvalues using the QR Algorithm\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Task 4**: Complete the function `compute_eigenvalues`, which computes the eigenvalues of the square matrix $A$ using the QR algorithm. The function should return the vector of eigenvalues as the output. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eigenvalues(A):\n",
    "    eigvals = np.random.random(A.shape[1])\n",
    "\n",
    "    for i in range(100):\n",
    "        if i%2 == 0:\n",
    "            Q, R = QR_decomposition_Householder(A)\n",
    "            A = Q@R\n",
    "        else:\n",
    "            A = R@Q\n",
    "\n",
    "    eigvals = np.diag(A)\n",
    "\n",
    "    return eigvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the implementation on a random matrix $A$, which has real eigenvalues. We can easily generate such a matrix using the diagonalization\n",
    "\\begin{equation}\n",
    "A = S \\Lambda S^{-1}\n",
    "\\end{equation}\n",
    "We first generate a diagonal matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6\n",
    "Lambda = np.diag(np.random.rand(N)*10)\n",
    "print(Lambda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate a square random $S$ matrix. Note that this matrix will be invertible with almost certain probability. Using $S$ and $\\Lambda$, we can generate a random matrix with real eigenvalues to test the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.random.random((N,N))\n",
    "Sinv = np.linalg.inv(S)\n",
    "A = S@Lambda@Sinv\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues of $A$ can be easily found by using the `numpy.linalg.eigvals` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvaluesOfA = np.linalg.eigvals(A)\n",
    "print(eigenvaluesOfA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use 'compute_eigenvalues'. If the implementation is correct, it should return exactly the same values as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvaluesOfA = compute_eigenvalues(A)\n",
    "print(eigenvaluesOfA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
